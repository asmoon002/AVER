{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실행 순서\n",
    "\n",
    "1. 1셀 test_weight_file 필요한 시드 웨이트 파일로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "test_weight_file = \"0208_1726_seed_2_tlab_mh_model.pt\"\n",
    "SEED = int(test_weight_file.split(\"_\")[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "from train import train\n",
    "from val import validate\n",
    "from test import Test\n",
    "from utils.parser import parse_configuration\n",
    "import numpy as np\n",
    "from models.orig_cam import TLAB_CAM as Custom_CAModel\n",
    "from models.tsav import TwoStreamAuralVisualModel\n",
    "from datasets.dataset_val import ImageList_val\n",
    "from losses.loss import CCCLoss\n",
    "from datetime import datetime\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize network with xavier\n",
      "Saved cammodel_accV :  0.6523806767948108\n",
      "Saved cammodel_accA :  0.6131158270799947\n",
      "Number of Sequences: 83\n"
     ]
    }
   ],
   "source": [
    "TrainingAccuracy_V = []\n",
    "TrainingAccuracy_A = []\n",
    "ValidationAccuracy_V = []\n",
    "ValidationAccuracy_A = []\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "\n",
    "class ValPadSequence:\n",
    "\tdef __call__(self, sorted_batch):\n",
    "\n",
    "\t\tsequences = [x[0] for x in sorted_batch]\n",
    "\t\taud_sequences = [x[1] for x in sorted_batch]\n",
    "\t\tspec_dim = []\n",
    "\t\tfor aud in aud_sequences:\n",
    "\t\t\tspec_dim.append(aud.shape[3])\n",
    "\n",
    "\t\tmax_spec_dim = max(spec_dim)\n",
    "\t\taudio_features = torch.zeros(len(spec_dim), 16, 1, 64, max_spec_dim)\n",
    "\t\tfor batch_idx, spectrogram in enumerate(aud_sequences):\n",
    "\t\t\tif spectrogram.shape[2] < max_spec_dim:\n",
    "\t\t\t\taudio_features[batch_idx, :, :, :, -spectrogram.shape[3]:] = spectrogram\n",
    "\t\t\telse:\n",
    "\t\t\t\taudio_features[batch_idx, :,:, :, :] = spectrogram\n",
    "\n",
    "\t\tframeids = [x[2] for x in sorted_batch]\n",
    "\t\tv_ids = [x[3] for x in sorted_batch]\n",
    "\t\tv_lengths = [x[4] for x in sorted_batch]\n",
    "\t\tlabelV = [x[5] for x in sorted_batch]\n",
    "\t\tlabelA = [x[6] for x in sorted_batch]\n",
    "\n",
    "\t\tvisual_sequences = torch.stack(sequences)\n",
    "\t\tlabelsV = torch.stack(labelV)\n",
    "\t\tlabelsA = torch.stack(labelA)\n",
    "\t\treturn visual_sequences, audio_features, frameids, v_ids, v_lengths, labelsV, labelsA\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_path = 'ABAW2020TNT/model2/TSAV_Sub4_544k.pth.tar' # path to the model\n",
    "model = TwoStreamAuralVisualModel(num_channels=4)\n",
    "saved_model = torch.load(model_path)\n",
    "model.load_state_dict(saved_model['state_dict'])\n",
    "\n",
    "new_first_layer = nn.Conv3d(in_channels=3,\n",
    "\t\t\t\t\tout_channels=model.video_model.r2plus1d.stem[0].out_channels,\n",
    "\t\t\t\t\tkernel_size=model.video_model.r2plus1d.stem[0].kernel_size,\n",
    "\t\t\t\t\tstride=model.video_model.r2plus1d.stem[0].stride,\n",
    "\t\t\t\t\tpadding=model.video_model.r2plus1d.stem[0].padding,\n",
    "\t\t\t\t\tbias=False)\n",
    "\n",
    "new_first_layer.weight.data = model.video_model.r2plus1d.stem[0].weight.data[:, 0:3]\n",
    "model.video_model.r2plus1d.stem[0] = new_first_layer\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "### Freezing the model\n",
    "for p in model.parameters():\n",
    "\tp.requires_grad = False\n",
    "for p in model.children():\n",
    "\tp.train(False)\n",
    " \n",
    "fusion_model = Custom_CAModel()\n",
    "# fusion_model = nn.DataParallel(fusion_model)\n",
    "# fusion_model.cuda()\n",
    "fusion_model = fusion_model.to(device=device)\n",
    "\n",
    "cam_model_path = f'SavedWeights/{test_weight_file}' # path to the model\n",
    "cam_saved_model = torch.load(cam_model_path)\n",
    "fusion_model.load_state_dict(cam_saved_model['net'])\n",
    "cammodel_accV = torch.load(cam_model_path)['best_Val_accV']\n",
    "cammodel_accA = torch.load(cam_model_path)['best_Val_accA']\n",
    "print(\"Saved cammodel_accV : \", cammodel_accV)\n",
    "print(\"Saved cammodel_accA : \", cammodel_accA)\n",
    "for param in fusion_model.parameters():  # children():\n",
    "    param.requires_grad = False\n",
    "\n",
    "config = \"config_file.json\"\n",
    "configuration = parse_configuration(config)\n",
    "\n",
    "dataset_rootpath = configuration['dataset_rootpath']\n",
    "dataset_wavspath = configuration['dataset_wavspath']\n",
    "dataset_labelpath = configuration['labelpath']\n",
    "\n",
    "def load_partition_set(partition_path, seed):\n",
    "\timport json\n",
    "\n",
    "\twith open(partition_path, 'r') as f:    \n",
    "\t\tseed_data = json.load(f)\n",
    "\n",
    "\tseed_data_train = seed_data[f'seed_{seed}']['Train_Set']\n",
    "\tseed_data_valid = seed_data[f'seed_{seed}']['Validation_Set']\n",
    "\tseed_data_test  = seed_data[f'seed_{seed}']['Test_Set']\n",
    " \n",
    "\tseed_data_train = [fn + \".csv\" for fn in seed_data_train]\n",
    "\tseed_data_valid = [fn + \".csv\" for fn in seed_data_valid]\n",
    "\tseed_data_test  = [fn + \".csv\" for fn in seed_data_test ]\n",
    "\n",
    "\treturn seed_data_train, seed_data_valid, seed_data_test\n",
    "\n",
    "partition_path = \"../data/Affwild2/seed_data.json\"\n",
    "train_set, valid_set, test_set = load_partition_set(partition_path, SEED)\n",
    "\n",
    "init_time = datetime.now()\n",
    "init_time = init_time.strftime('%m%d_%H%M')\n",
    "\n",
    "criterion = CCCLoss(digitize_num=1).cuda()\n",
    "\n",
    "testdataset = ImageList_val(root=configuration['dataset_rootpath'], fileList=test_set, labelPath=dataset_labelpath,\n",
    "\t\t\t\t\taudList=configuration['dataset_wavspath'], length=configuration['test_params']['seq_length'],\n",
    "\t\t\t\t\tflag='Test', stride=configuration['test_params']['stride'], dilation = configuration['test_params']['dilation'],\n",
    "\t\t\t\t\tsubseq_length = configuration['test_params']['subseq_length'])\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "\t\t\ttestdataset, collate_fn=ValPadSequence(),\n",
    "\t\t\t**configuration['test_params']['loader_params'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.optim\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "import numpy as np\n",
    "import sys\n",
    "from EvaluationMetrics.cccmetric import ccc\n",
    "\n",
    "\n",
    "def Test(val_loader, model, criterion, cam):\n",
    "    # switch to evaluate mode\n",
    "    global Val_acc\n",
    "    global best_Val_acc\n",
    "    global best_Val_acc_epoch\n",
    "    #model.eval()\n",
    "    model.eval()\n",
    "    cam.eval()\n",
    "\n",
    "    vout = []\n",
    "    vtar = []\n",
    "    aout = []\n",
    "    atar = []\n",
    "\t#torch.cuda.synchronize()\n",
    "    #t7 = time.time()\n",
    "    pred_a = dict()\n",
    "    pred_v = dict()\n",
    "    label_a = dict()\n",
    "    label_v = dict()\n",
    "\t#files_dict = {}\n",
    "    count = 0\n",
    "    \n",
    "    vid_pred = {}\n",
    "    vid_label = {}\n",
    "    vid_ccc = {}\n",
    "    global_vid_fts, global_aud_fts= None, None\n",
    "    \n",
    "    for batch_idx, (visualdata, audiodata, frame_ids, videos, vid_lengths, labelsV, labelsA) in tqdm(enumerate(val_loader),\n",
    "                                                            total=len(val_loader), position=0, leave=True):\n",
    "        \n",
    "        audiodata = audiodata.cuda()#.unsqueeze(2)\n",
    "        visualdata = visualdata.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            b, seq_t, c, subseq_t, h, w = visualdata.size()\n",
    "            visual_feats = torch.empty((b, seq_t, 25088), dtype=visualdata.dtype, device = visualdata.device)\n",
    "            aud_feats = torch.empty((b, seq_t, 512), dtype=visualdata.dtype, device = visualdata.device)\n",
    "            for i in range(visualdata.shape[0]):\n",
    "                audio_feat, visualfeat, _ = model(audiodata[i,:,:,:], visualdata[i, :, :, :,:,:])\n",
    "                visual_feats[i,:,:] = visualfeat\n",
    "                aud_feats[i,:,:] = audio_feat\n",
    "\n",
    "            audiovisual_vouts,audiovisual_aouts = cam(aud_feats, visual_feats)\n",
    "\n",
    "            audiovisual_vouts = audiovisual_vouts.detach().cpu().numpy()\n",
    "            audiovisual_aouts = audiovisual_aouts.detach().cpu().numpy()\n",
    "\n",
    "            labelsV = labelsV.cpu().numpy()\n",
    "            labelsA = labelsA.cpu().numpy()\n",
    "\n",
    "            for voutputs, aoutputs, labelV, labelA, frameids, video, vid_length in zip(audiovisual_vouts, audiovisual_aouts, labelsV, labelsA, frame_ids, videos, vid_lengths):\n",
    "                for voutput, aoutput, labV, labA, frameid, vid, length in zip(voutputs, aoutputs, labelV, labelA, frameids, video, vid_length):\n",
    "                    if vid not in pred_a:\n",
    "                        if frameid>1:\n",
    "                            print(vid)\n",
    "                            print(length)\n",
    "                            print(\"something is wrong\")\n",
    "                            sys.exit()\n",
    "                        count = count + 1\n",
    "\n",
    "                        pred_a[vid] = [0]*length\n",
    "                        pred_v[vid] = [0]*length\n",
    "                        label_a[vid] = [0]*length\n",
    "                        label_v[vid] = [0]*length\n",
    "                        if labV == -5.0:\n",
    "                            continue\n",
    "                        pred_a[vid][frameid-1] = aoutput\n",
    "                        pred_v[vid][frameid-1] = voutput\n",
    "                        label_a[vid][frameid-1] = labA\n",
    "                        label_v[vid][frameid-1] = labV\n",
    "                    else:\n",
    "                        if frameid <= length:\n",
    "                            if labV == -5.0:\n",
    "                                continue\n",
    "                            pred_a[vid][frameid-1] = aoutput\n",
    "                            pred_v[vid][frameid-1] = voutput\n",
    "                            label_a[vid][frameid-1] = labA\n",
    "                            label_v[vid][frameid-1] = labV\n",
    "                            \n",
    "\n",
    "    for idx, key in enumerate(pred_a.keys()):\n",
    "        clipped_preds_v = np.clip(pred_v[key], -1.0, 1.0)\n",
    "        clipped_preds_a = np.clip(pred_a[key], -1.0, 1.0)\n",
    "\n",
    "        smoothened_preds_v = uniform_filter1d(clipped_preds_v, size=20, mode='constant')\n",
    "        smoothened_preds_a = uniform_filter1d(clipped_preds_a, size=50, mode='constant')\n",
    "        tars_v = label_v[key]\n",
    "        tars_a = label_a[key]\n",
    "        \n",
    "        key_vout = []\n",
    "        key_aout = []\n",
    "        key_vtar = []\n",
    "        key_atar = []\n",
    "\n",
    "        for i in range(len(smoothened_preds_a)):\n",
    "            vout.append(smoothened_preds_v[i])\n",
    "            aout.append(smoothened_preds_a[i])\n",
    "            vtar.append(tars_v[i])\n",
    "            atar.append(tars_a[i])\n",
    "            \n",
    "            key_vout.append(smoothened_preds_v[i])\n",
    "            key_aout.append(smoothened_preds_a[i])\n",
    "            key_vtar.append(tars_v[i])\n",
    "            key_atar.append(tars_a[i])\n",
    "                \n",
    "        vid_pred[key] = {\"vout\": type(key_vout), \"aout\": type(key_aout)}\n",
    "        vid_label[key] = {\"vtar\": type(key_vtar), \"atar\": type(key_atar)}\n",
    "        vid_ccc[key] = {\"vccc\": 0, \"accc\": 0}\n",
    "\n",
    "        vid_pred[key][\"vout\"] = key_vout\n",
    "        vid_pred[key][\"aout\"] = key_aout\n",
    "        vid_label[key][\"vtar\"] = key_vtar\n",
    "        vid_label[key][\"atar\"] = key_atar\n",
    "        vid_ccc[key]['vccc'] = ccc(np.array(key_vout), np.array(key_vtar))\n",
    "        vid_ccc[key]['accc'] = ccc(np.array(key_aout), np.array(key_atar))\n",
    "        \n",
    "\n",
    "    accV = ccc(np.array(vout), np.array(vtar))\n",
    "    accA = ccc(np.array(aout), np.array(atar))\n",
    "\n",
    "    print(accV)\n",
    "    print(accA)\n",
    "    return accV, accA, vid_pred, vid_label, vid_ccc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Test samples:27805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1738/1738 [1:01:33<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6593884484570371\n",
      "0.5748548647364081\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Test samples:\" + str(len(testdataset)))\n",
    "Test_vacc, Test_aacc, vid_pred, vid_label, vid_ccc = Test(testloader, model, criterion, fusion_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'129-24-1280x720': [0.03946424752978955,\n",
       "  0.1641334872964913,\n",
       "  0.10179886741314043],\n",
       " '231': [0.6131030307374666, 0.6371767923660491, 0.6251399115517579],\n",
       " '29-24-1280x720': [0.06313698151881204,\n",
       "  0.37817577367951566,\n",
       "  0.22065637759916384],\n",
       " '135-24-1920x1080_left': [-0.04364435570128061,\n",
       "  0.23496987240835576,\n",
       "  0.09566275835353757],\n",
       " '203': [0.13871790050917523, 0.6094388059636384, 0.3740783532364068],\n",
       " '329': [0.41101290478527636, 0.5666165683922765, 0.4888147365887764],\n",
       " '133': [0.06162022846439198, 0.4481312122090452, 0.2548757203367186],\n",
       " '20-24-1920x1080': [0.01955354847183874,\n",
       "  0.4623707125891792,\n",
       "  0.24096213053050897],\n",
       " '75-30-960x720': [0.11657277105993592,\n",
       "  0.13032154071561663,\n",
       "  0.12344715588777627],\n",
       " '406': [-0.04058687797541296, 0.2128029302845287, 0.08610802615455787],\n",
       " '30-30-1920x1080_right': [-0.2115102379432637,\n",
       "  0.47038035371188314,\n",
       "  0.1294350578843097],\n",
       " '95-24-1920x1080': [0.4665253190036166,\n",
       "  0.1599219336402356,\n",
       "  0.31322362632192613],\n",
       " '252': [0.5027782205596957, 0.3766397577838743, 0.439708989171785],\n",
       " '297': [0.020514734647405, 0.26387636898805755, 0.14219555181773127],\n",
       " '331': [0.5438195366921047, 0.5635834525234347, 0.5537014946077696],\n",
       " '136': [0.7127255179870421, 0.6586314192116159, 0.685678468599329],\n",
       " '308': [0.06393397394799503, 0.13709173531190288, 0.10051285462994897],\n",
       " '127': [0.375433542971305, 0.36773475315410586, 0.37158414806270545],\n",
       " '94-30-1920x1080': [0.2172397963865858,\n",
       "  -0.015119576956091618,\n",
       "  0.10106010971524709],\n",
       " '161': [0.6375459775140123, 0.4657083572428743, 0.5516271673784433],\n",
       " '225': [0.4131299919011756, 0.42800309922959207, 0.42056654556538386],\n",
       " '214': [0.0783128477686181, 0.3885784690233211, 0.2334456583959696],\n",
       " '261': [0.48425204599746735, 0.3388545249139309, 0.41155328545569914],\n",
       " '306': [0.8463635467759549, 0.7264740633146043, 0.7864188050452796],\n",
       " '354': [0.3457441485816589, 0.19539231118817374, 0.27056822988491636],\n",
       " '433': [0.5397181557955998, 0.569938627876838, 0.5548283918362189],\n",
       " '146': [0.36585361674034583, 0.2723580987787724, 0.31910585775955913],\n",
       " '202': [0.3413487930296004, 0.7596732010486509, 0.5505109970391256],\n",
       " '168': [0.44071230360733177, 0.47310524241039087, 0.45690877300886135],\n",
       " '135': [0.6166673744384434, 0.5929956368601941, 0.6048315056493188],\n",
       " '420': [0.3719812740382431, 0.318235687127885, 0.3451084805830641],\n",
       " '317': [0.6497556873770234, 0.7377083629208467, 0.6937320251489351],\n",
       " '221': [0.15023007439005787, 0.43646104242814343, 0.29334555840910065],\n",
       " '384': [0.09041510380514758, 0.32855102952951887, 0.20948306666733324],\n",
       " '120': [0.3632158032537609, 0.5961349112713551, 0.479675357262558],\n",
       " '223': [0.23286458852400502, 0.17449084509554622, 0.20367771680977562],\n",
       " '347': [0.5128503266576666, 0.4422330280269947, 0.47754167734233066],\n",
       " '326': [0.3275221703918247, 0.3229756018945244, 0.32524888614317454],\n",
       " '449': [0.015595817993571277, 0.048933790270581166, 0.03226480413207622],\n",
       " '175': [0.8464567922109991, 0.7787457551313092, 0.8126012736711541],\n",
       " '131': [0.16758853420321612, 0.10697551677592147, 0.1372820254895688],\n",
       " '87-25-1920x1080': [-0.030722798631315357,\n",
       "  0.25264448494579345,\n",
       "  0.11096084315723904],\n",
       " '189': [0.5875068293201547, 0.41432134638748647, 0.5009140878538206],\n",
       " '328': [0.16998727441239467, 0.5570722057400368, 0.36352974007621575],\n",
       " '201': [-0.08581027485107792, 0.07775492054541218, -0.004027677152832872],\n",
       " '114': [0.5950567833171071, 0.046431443854214514, 0.3207441135856608],\n",
       " '28-30-1280x720-1': [0.3385711187564317,\n",
       "  0.359259965645995,\n",
       "  0.34891554220121335],\n",
       " '118': [0.34925312380461937, 0.4187521064625873, 0.38400261513360334],\n",
       " '275': [0.7489996924462611, 0.7098776077053566, 0.7294386500758088],\n",
       " '373': [0.3887469657511279, 0.5041941808700102, 0.44647057331056905],\n",
       " '206': [-0.14055998264121541, 0.24409857612648436, 0.051769296742634474],\n",
       " '388': [0.28943558633353694, -0.007084800931263052, 0.14117539270113694],\n",
       " '400': [0.2903968003906117, 0.25806913757369815, 0.27423296898215493],\n",
       " '44-25-426x240': [0.0014460688518784259,\n",
       "  -0.003604730561102446,\n",
       "  -0.0010793308546120102],\n",
       " '427': [0.6984611563998289, 0.5755219318482312, 0.63699154412403],\n",
       " '246': [0.9329713642363493, 0.7302250694393476, 0.8315982168378484],\n",
       " '122-60-1920x1080-3': [0.37157412743661905,\n",
       "  0.47111546791704234,\n",
       "  0.4213447976768307],\n",
       " '4-30-1920x1080': [0.3200997410269028, 0.400255813450697, 0.3601777772387999],\n",
       " '37-30-1280x720': [0.08004880175490975,\n",
       "  0.10946501779820537,\n",
       "  0.09475690977655757],\n",
       " '111-25-1920x1080': [0.2819764548164796,\n",
       "  0.23428546040921241,\n",
       "  0.258130957612846],\n",
       " '39-25-424x240': [-0.0033457328658376157,\n",
       "  0.5751882290992275,\n",
       "  0.28592124811669495],\n",
       " '309': [-0.05626731921627507, 0.4857159274853102, 0.21472430413451754],\n",
       " '22-30-1920x1080': [-0.025467232850518266,\n",
       "  0.49595134797451496,\n",
       "  0.23524205756199834],\n",
       " '220': [-0.12268062668460028, 0.3012791054928824, 0.08929923940414106],\n",
       " '89-30-1080x1920': [0.7218193940819058,\n",
       "  0.5723007314696015,\n",
       "  0.6470600627757537],\n",
       " '218': [0.17152294440165797, 0.4816229600028006, 0.32657295220222926],\n",
       " '245': [0.047900749596731025, 0.4951897429561493, 0.27154524627644017],\n",
       " '136-30-1920x1080': [0.23386799684968276,\n",
       "  0.6477474801591694,\n",
       "  0.44080773850442606],\n",
       " '362': [0.13303122990667585, 0.314079410828046, 0.22355532036736092],\n",
       " '264': [0.627585385550346, 0.1718433284980987, 0.39971435702422237],\n",
       " '13-30-1920x1080': [0.03158004731104694,\n",
       "  0.021244599049331826,\n",
       "  0.026412323180189382],\n",
       " 'video88': [0.48418107179124714, 0.7050783787141676, 0.5946297252527073],\n",
       " '132-30-426x240': [0.38403994389378676,\n",
       "  0.1899736634359143,\n",
       "  0.28700680366485054],\n",
       " 'video75': [-0.03832927552334858,\n",
       "  0.014496711390413987,\n",
       "  -0.011916282066467297],\n",
       " '112-30-640x360': [-0.017236127176236186,\n",
       "  0.05873115285631995,\n",
       "  0.02074751284004188],\n",
       " 'video71': [0.0325234572413134, 0.23884962599440887, 0.13568654161786114],\n",
       " '48-30-720x1280': [0.3060884313289857,\n",
       "  -0.15010595890337033,\n",
       "  0.0779912362128077],\n",
       " 'video59': [-0.01056049125405529, 0.27765842558366566, 0.1335489671648052],\n",
       " '21-24-1920x1080': [0.12056825910329678,\n",
       "  0.23566250281749093,\n",
       "  0.17811538096039387],\n",
       " 'video56': [0.14766319498026234, 0.37859726795465326, 0.2631302314674578],\n",
       " 'video57': [-0.001716099140095204, 0.05922922845699589, 0.02875656465845034],\n",
       " 'video86_2': [0.10577295218128951, 0.18591742640323466, 0.1458451892922621],\n",
       " 'video78': [0.26488166553918135, 0.514622689402243, 0.38975217747071217]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_ccc_result = {} # {\"vi FF FFd\" : [valence, arousal, mean]}\n",
    "for k in vid_ccc.keys():\n",
    "    new_ccc_result[k] = [vid_ccc[k]['vccc'], vid_ccc[k]['accc'], np.mean([vid_ccc[k]['vccc'], vid_ccc[k]['accc']])]\n",
    "    \n",
    "new_ccc_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('video75',\n",
       "  [-0.03832927552334858, 0.014496711390413987, -0.011916282066467297]),\n",
       " ('201', [-0.08581027485107792, 0.07775492054541218, -0.004027677152832872]),\n",
       " ('44-25-426x240',\n",
       "  [0.0014460688518784259, -0.003604730561102446, -0.0010793308546120102]),\n",
       " ('112-30-640x360',\n",
       "  [-0.017236127176236186, 0.05873115285631995, 0.02074751284004188]),\n",
       " ('13-30-1920x1080',\n",
       "  [0.03158004731104694, 0.021244599049331826, 0.026412323180189382]),\n",
       " ('video57',\n",
       "  [-0.001716099140095204, 0.05922922845699589, 0.02875656465845034]),\n",
       " ('449', [0.015595817993571277, 0.048933790270581166, 0.03226480413207622]),\n",
       " ('206', [-0.14055998264121541, 0.24409857612648436, 0.051769296742634474]),\n",
       " ('48-30-720x1280',\n",
       "  [0.3060884313289857, -0.15010595890337033, 0.0779912362128077]),\n",
       " ('406', [-0.04058687797541296, 0.2128029302845287, 0.08610802615455787]),\n",
       " ('220', [-0.12268062668460028, 0.3012791054928824, 0.08929923940414106]),\n",
       " ('37-30-1280x720',\n",
       "  [0.08004880175490975, 0.10946501779820537, 0.09475690977655757]),\n",
       " ('135-24-1920x1080_left',\n",
       "  [-0.04364435570128061, 0.23496987240835576, 0.09566275835353757]),\n",
       " ('308', [0.06393397394799503, 0.13709173531190288, 0.10051285462994897]),\n",
       " ('94-30-1920x1080',\n",
       "  [0.2172397963865858, -0.015119576956091618, 0.10106010971524709]),\n",
       " ('129-24-1280x720',\n",
       "  [0.03946424752978955, 0.1641334872964913, 0.10179886741314043]),\n",
       " ('87-25-1920x1080',\n",
       "  [-0.030722798631315357, 0.25264448494579345, 0.11096084315723904]),\n",
       " ('75-30-960x720',\n",
       "  [0.11657277105993592, 0.13032154071561663, 0.12344715588777627]),\n",
       " ('30-30-1920x1080_right',\n",
       "  [-0.2115102379432637, 0.47038035371188314, 0.1294350578843097]),\n",
       " ('video59', [-0.01056049125405529, 0.27765842558366566, 0.1335489671648052]),\n",
       " ('video71', [0.0325234572413134, 0.23884962599440887, 0.13568654161786114]),\n",
       " ('131', [0.16758853420321612, 0.10697551677592147, 0.1372820254895688]),\n",
       " ('388', [0.28943558633353694, -0.007084800931263052, 0.14117539270113694]),\n",
       " ('297', [0.020514734647405, 0.26387636898805755, 0.14219555181773127]),\n",
       " ('video86_2', [0.10577295218128951, 0.18591742640323466, 0.1458451892922621]),\n",
       " ('21-24-1920x1080',\n",
       "  [0.12056825910329678, 0.23566250281749093, 0.17811538096039387]),\n",
       " ('223', [0.23286458852400502, 0.17449084509554622, 0.20367771680977562]),\n",
       " ('384', [0.09041510380514758, 0.32855102952951887, 0.20948306666733324]),\n",
       " ('309', [-0.05626731921627507, 0.4857159274853102, 0.21472430413451754]),\n",
       " ('29-24-1280x720',\n",
       "  [0.06313698151881204, 0.37817577367951566, 0.22065637759916384]),\n",
       " ('362', [0.13303122990667585, 0.314079410828046, 0.22355532036736092]),\n",
       " ('214', [0.0783128477686181, 0.3885784690233211, 0.2334456583959696]),\n",
       " ('22-30-1920x1080',\n",
       "  [-0.025467232850518266, 0.49595134797451496, 0.23524205756199834]),\n",
       " ('20-24-1920x1080',\n",
       "  [0.01955354847183874, 0.4623707125891792, 0.24096213053050897]),\n",
       " ('133', [0.06162022846439198, 0.4481312122090452, 0.2548757203367186]),\n",
       " ('111-25-1920x1080',\n",
       "  [0.2819764548164796, 0.23428546040921241, 0.258130957612846]),\n",
       " ('video56', [0.14766319498026234, 0.37859726795465326, 0.2631302314674578]),\n",
       " ('354', [0.3457441485816589, 0.19539231118817374, 0.27056822988491636]),\n",
       " ('245', [0.047900749596731025, 0.4951897429561493, 0.27154524627644017]),\n",
       " ('400', [0.2903968003906117, 0.25806913757369815, 0.27423296898215493]),\n",
       " ('39-25-424x240',\n",
       "  [-0.0033457328658376157, 0.5751882290992275, 0.28592124811669495]),\n",
       " ('132-30-426x240',\n",
       "  [0.38403994389378676, 0.1899736634359143, 0.28700680366485054]),\n",
       " ('221', [0.15023007439005787, 0.43646104242814343, 0.29334555840910065]),\n",
       " ('95-24-1920x1080',\n",
       "  [0.4665253190036166, 0.1599219336402356, 0.31322362632192613]),\n",
       " ('146', [0.36585361674034583, 0.2723580987787724, 0.31910585775955913]),\n",
       " ('114', [0.5950567833171071, 0.046431443854214514, 0.3207441135856608]),\n",
       " ('326', [0.3275221703918247, 0.3229756018945244, 0.32524888614317454]),\n",
       " ('218', [0.17152294440165797, 0.4816229600028006, 0.32657295220222926]),\n",
       " ('420', [0.3719812740382431, 0.318235687127885, 0.3451084805830641]),\n",
       " ('28-30-1280x720-1',\n",
       "  [0.3385711187564317, 0.359259965645995, 0.34891554220121335]),\n",
       " ('4-30-1920x1080',\n",
       "  [0.3200997410269028, 0.400255813450697, 0.3601777772387999]),\n",
       " ('328', [0.16998727441239467, 0.5570722057400368, 0.36352974007621575]),\n",
       " ('127', [0.375433542971305, 0.36773475315410586, 0.37158414806270545]),\n",
       " ('203', [0.13871790050917523, 0.6094388059636384, 0.3740783532364068]),\n",
       " ('118', [0.34925312380461937, 0.4187521064625873, 0.38400261513360334]),\n",
       " ('video78', [0.26488166553918135, 0.514622689402243, 0.38975217747071217]),\n",
       " ('264', [0.627585385550346, 0.1718433284980987, 0.39971435702422237]),\n",
       " ('261', [0.48425204599746735, 0.3388545249139309, 0.41155328545569914]),\n",
       " ('225', [0.4131299919011756, 0.42800309922959207, 0.42056654556538386]),\n",
       " ('122-60-1920x1080-3',\n",
       "  [0.37157412743661905, 0.47111546791704234, 0.4213447976768307]),\n",
       " ('252', [0.5027782205596957, 0.3766397577838743, 0.439708989171785]),\n",
       " ('136-30-1920x1080',\n",
       "  [0.23386799684968276, 0.6477474801591694, 0.44080773850442606]),\n",
       " ('373', [0.3887469657511279, 0.5041941808700102, 0.44647057331056905]),\n",
       " ('168', [0.44071230360733177, 0.47310524241039087, 0.45690877300886135]),\n",
       " ('347', [0.5128503266576666, 0.4422330280269947, 0.47754167734233066]),\n",
       " ('120', [0.3632158032537609, 0.5961349112713551, 0.479675357262558]),\n",
       " ('329', [0.41101290478527636, 0.5666165683922765, 0.4888147365887764]),\n",
       " ('189', [0.5875068293201547, 0.41432134638748647, 0.5009140878538206]),\n",
       " ('202', [0.3413487930296004, 0.7596732010486509, 0.5505109970391256]),\n",
       " ('161', [0.6375459775140123, 0.4657083572428743, 0.5516271673784433]),\n",
       " ('331', [0.5438195366921047, 0.5635834525234347, 0.5537014946077696]),\n",
       " ('433', [0.5397181557955998, 0.569938627876838, 0.5548283918362189]),\n",
       " ('video88', [0.48418107179124714, 0.7050783787141676, 0.5946297252527073]),\n",
       " ('135', [0.6166673744384434, 0.5929956368601941, 0.6048315056493188]),\n",
       " ('231', [0.6131030307374666, 0.6371767923660491, 0.6251399115517579]),\n",
       " ('427', [0.6984611563998289, 0.5755219318482312, 0.63699154412403]),\n",
       " ('89-30-1080x1920',\n",
       "  [0.7218193940819058, 0.5723007314696015, 0.6470600627757537]),\n",
       " ('136', [0.7127255179870421, 0.6586314192116159, 0.685678468599329]),\n",
       " ('317', [0.6497556873770234, 0.7377083629208467, 0.6937320251489351]),\n",
       " ('275', [0.7489996924462611, 0.7098776077053566, 0.7294386500758088]),\n",
       " ('306', [0.8463635467759549, 0.7264740633146043, 0.7864188050452796]),\n",
       " ('175', [0.8464567922109991, 0.7787457551313092, 0.8126012736711541]),\n",
       " ('246', [0.9329713642363493, 0.7302250694393476, 0.8315982168378484])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sort_vid = sorted(new_ccc_result.items(), key=lambda x: x[1][2])\n",
    "sort_vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import openpyxl\n",
    "\n",
    "xl_dir_path = \"xl_dir\"\n",
    "if not os.path.exists(xl_dir_path):\n",
    "    os.makedirs(xl_dir_path)\n",
    "\n",
    "columns = [\"file_name\", \"infer_val\", \"infer_aro\", \"infer_mean\", \"anno_val\", \"anno_aro\", \"anno_mean\"]\n",
    "file_values_dict = {c:[] for c in columns}\n",
    "\n",
    "columns = list(file_values_dict.keys())\n",
    "orig_label = vid_label\n",
    "\n",
    "for vid,score_list in sort_vid:\n",
    "    file_values_dict['file_name'].append(vid)\n",
    "    \n",
    "    file_values_dict['infer_val'].append(np.round(score_list[0], 3))\n",
    "    file_values_dict['infer_aro'].append(np.round(score_list[1], 3))\n",
    "    file_values_dict['infer_mean'].append(np.round(score_list[2], 3))\n",
    "    \n",
    "    \n",
    "    orig_label_arousal = np.mean(orig_label[vid]['atar'])\n",
    "    orig_label_valence = np.mean(orig_label[vid]['vtar'])\n",
    "    \n",
    "    file_values_dict['anno_val'].append(np.round(orig_label_arousal, 3))\n",
    "    file_values_dict['anno_aro'].append(np.round(orig_label_valence, 3))\n",
    "    \n",
    "    orig_label_mean = np.mean([orig_label_arousal, orig_label_valence])\n",
    "    file_values_dict['anno_mean'].append(np.round(orig_label_mean, 3))    \n",
    "    \n",
    "    \n",
    "xl_file_name = f\"tlab_mh_results_{SEED}.xlsx\"\n",
    "xl_file = os.path.join(xl_dir_path, xl_file_name)\n",
    "\n",
    "if not os.path.exists(xl_file):\n",
    "    wb=openpyxl.Workbook()\n",
    "    wb.save(xl_file)\n",
    "    \n",
    "full_record_df = pd.DataFrame(file_values_dict, columns=columns) # todo    \n",
    "    \n",
    "# full_records 시트를 작성하여 파일을 생성\n",
    "with pd.ExcelWriter(xl_file, mode='w', engine='openpyxl') as writer:\n",
    "    full_record_df.to_excel(writer, sheet_name=\"full_records\", index=False, encoding='utf-8')\n",
    "    \n",
    "with pd.ExcelWriter(xl_file, mode='a', engine='openpyxl') as writer:\n",
    "    for vid, scores in sort_vid:\n",
    "        va_df_dict = {\n",
    "            \"pred_val\" : [],\n",
    "            \"pred_aro\" : [],\n",
    "            \"label_val\" : [],\n",
    "            \"label_aro\" : []\n",
    "        }\n",
    "        va_df_dict[\"pred_val\"].extend(vid_pred[vid]['vout'])\n",
    "        va_df_dict[\"pred_aro\"].extend(vid_pred[vid]['aout'])\n",
    "        va_df_dict[\"label_val\"].extend(vid_label[vid]['vtar'])\n",
    "        va_df_dict[\"label_aro\"].extend(vid_label[vid]['atar'])\n",
    "        \n",
    "        va_df = pd.DataFrame(va_df_dict, columns=va_df_dict.keys())\n",
    "        va_df.to_excel(writer, sheet_name=vid, index=False)\n",
    "        \n",
    "    writer.save()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = \"save/results/tlab_mh_results.csv\"\n",
    "record_v, record_a, record_m = f\"{Test_vacc:.3f}\", f\"{Test_aacc:.3f}\", f\"{np.mean([Test_vacc, Test_aacc]):.3f}\"\n",
    "\n",
    "result_col = [\"model\", \"seed\", \"Valence_ccc\", \"Arousal_ccc\", \"Mean_CCC\"]\n",
    "record = [test_weight_file, SEED, record_v, record_a, record_m]\n",
    "\n",
    "df = pd.DataFrame([record], columns=result_col)\n",
    "if not os.path.exists(result_path):\n",
    "    df.to_csv(result_path, index=False)\n",
    "else:\n",
    "    df.to_csv(result_path, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set에 대한 최종 표준편차까지 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>seed</th>\n",
       "      <th>Valence_ccc</th>\n",
       "      <th>Arousal_ccc</th>\n",
       "      <th>Mean_CCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0227_0408_seed_3_tlab_mh_model.pt</td>\n",
       "      <td>2</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0227_0408_seed_3_tlab_mh_model.pt</td>\n",
       "      <td>0</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0227_0408_seed_3_tlab_mh_model.pt</td>\n",
       "      <td>3</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model seed Valence_ccc Arousal_ccc Mean_CCC\n",
       "0  0227_0408_seed_3_tlab_mh_model.pt    2       0.652       0.568    0.610\n",
       "1  0227_0408_seed_3_tlab_mh_model.pt    0       0.227       0.492    0.360\n",
       "2  0227_0408_seed_3_tlab_mh_model.pt    3       0.311       0.558    0.434"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"save/results/tlab_mh_results.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "data = data[~(data['seed'] == \"result\")]\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# for k in data:\n",
    "#     data[k] = data[k].astype(np.float32)\n",
    "\n",
    "# display(data)\n",
    "\n",
    "res = {}\n",
    "res['model'] = 'all'\n",
    "res['seed'] = \"result\"\n",
    "res['Valence_ccc']  = f\"{np.mean(data['Valence_ccc']):.3f} ± {np.std(data['Valence_ccc']):.3f}\"\n",
    "res['Arousal_ccc']  = f\"{np.mean(data['Arousal_ccc']):.3f} ± {np.std(data['Arousal_ccc']):.3f}\"\n",
    "res['Mean_CCC']     = f\"{np.mean(data['Mean_CCC']):.3f} ± {np.std(data['Mean_CCC']):.3f}\"\n",
    "\n",
    "data['model'] = test_weight_file\n",
    "data['seed'] = data['seed'].apply(lambda x : f\"{x:.0f}\")\n",
    "data['Valence_ccc'] = data['Valence_ccc'].apply(lambda x : f\"{x:.3f}\")\n",
    "data['Arousal_ccc'] = data['Arousal_ccc'].apply(lambda x : f\"{x:.3f}\")\n",
    "data['Mean_CCC'] = data['Mean_CCC'].apply(lambda x : f\"{x:.3f}\")\n",
    "\n",
    "display(data)\n",
    "\n",
    "data = data.append(res, ignore_index=True)\n",
    "data.to_csv(data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the Excel file\n",
    "# file_path22 = 'xl_dir/paper3_score_csv_file_0_nan387.xlsx'\n",
    "\n",
    "# # Load the 'full_records' sheet\n",
    "# old_data = pd.read_excel(file_path22, sheet_name='full_records')\n",
    "\n",
    "# # Display the first few rows of the dataframe to understand its structure\n",
    "# old_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# data = old_data[~((old_data['file_name'] == '387') & (old_data['file_name'] == '389'))]\n",
    "# np.mean(data.loc[:, ['infer_val', 'infer_aro', 'infer_mean']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Multimodal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
